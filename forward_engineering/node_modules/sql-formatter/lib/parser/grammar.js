"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports["default"] = void 0;

var _LexerAdapter = _interopRequireDefault(require("./LexerAdapter"));

var _ast = require("./ast");

var _token = require("../lexer/token");

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { "default": obj }; }

function _toConsumableArray(arr) { return _arrayWithoutHoles(arr) || _iterableToArray(arr) || _unsupportedIterableToArray(arr) || _nonIterableSpread(); }

function _nonIterableSpread() { throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); }

function _iterableToArray(iter) { if (typeof Symbol !== "undefined" && iter[Symbol.iterator] != null || iter["@@iterator"] != null) return Array.from(iter); }

function _arrayWithoutHoles(arr) { if (Array.isArray(arr)) return _arrayLikeToArray(arr); }

function _slicedToArray(arr, i) { return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _unsupportedIterableToArray(arr, i) || _nonIterableRest(); }

function _nonIterableRest() { throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method."); }

function _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === "string") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === "Object" && o.constructor) n = o.constructor.name; if (n === "Map" || n === "Set") return Array.from(o); if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }

function _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }

function _iterableToArrayLimit(arr, i) { var _i = arr == null ? null : typeof Symbol !== "undefined" && arr[Symbol.iterator] || arr["@@iterator"]; if (_i == null) return; var _arr = []; var _n = true; var _d = false; var _s, _e; try { for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i["return"] != null) _i["return"](); } finally { if (_d) throw _e; } } return _arr; }

function _arrayWithHoles(arr) { if (Array.isArray(arr)) return arr; }

// Generated automatically by nearley, version 2.20.1
// http://github.com/Hardmath123/nearley
// Bypasses TS6133. Allow declared but unused functions.
// @ts-ignore
function id(d) {
  return d[0];
}

// The lexer here is only to provide the has() method,
// that's used inside the generated grammar definition.
// A proper lexer gets passed to Nearley Parser constructor.
var lexer = new _LexerAdapter["default"](function (chunk) {
  return [];
}); // Used for unwrapping grammar rules like:
//
//   rule -> ( foo | bar | baz )
//
// which otherwise produce single element nested inside two arrays

var unwrap = function unwrap(_ref) {
  var _ref2 = _slicedToArray(_ref, 1),
      _ref2$ = _slicedToArray(_ref2[0], 1),
      el = _ref2$[0];

  return el;
};

var toKeywordNode = function toKeywordNode(token) {
  return {
    type: _ast.NodeType.keyword,
    tokenType: token.type,
    text: token.text,
    raw: token.raw
  };
};

;
;
;
;
var grammar = {
  Lexer: lexer,
  ParserRules: [{
    "name": "main$ebnf$1",
    "symbols": []
  }, {
    "name": "main$ebnf$1",
    "symbols": ["main$ebnf$1", "statement"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "main",
    "symbols": ["main$ebnf$1"],
    "postprocess": function postprocess(_ref3) {
      var _ref4 = _slicedToArray(_ref3, 1),
          statements = _ref4[0];

      var last = statements[statements.length - 1];

      if (last && !last.hasSemicolon) {
        // we have fully parsed the whole file
        // discard the last statement when it's empty
        return last.children.length > 0 ? statements : statements.slice(0, -1);
      } else {
        // parsing still in progress, do nothing
        return statements;
      }
    }
  }, {
    "name": "statement$subexpression$1",
    "symbols": [lexer.has("DELIMITER") ? {
      type: "DELIMITER"
    } : DELIMITER]
  }, {
    "name": "statement$subexpression$1",
    "symbols": [lexer.has("EOF") ? {
      type: "EOF"
    } : EOF]
  }, {
    "name": "statement",
    "symbols": ["expressions_or_clauses", "statement$subexpression$1"],
    "postprocess": function postprocess(_ref5) {
      var _ref6 = _slicedToArray(_ref5, 2),
          children = _ref6[0],
          _ref6$ = _slicedToArray(_ref6[1], 1),
          delimiter = _ref6$[0];

      return {
        type: _ast.NodeType.statement,
        children: children,
        hasSemicolon: delimiter.type === _token.TokenType.DELIMITER
      };
    }
  }, {
    "name": "expressions_or_clauses$ebnf$1",
    "symbols": []
  }, {
    "name": "expressions_or_clauses$ebnf$1",
    "symbols": ["expressions_or_clauses$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "expressions_or_clauses$ebnf$2",
    "symbols": []
  }, {
    "name": "expressions_or_clauses$ebnf$2",
    "symbols": ["expressions_or_clauses$ebnf$2", "clause"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "expressions_or_clauses",
    "symbols": ["expressions_or_clauses$ebnf$1", "expressions_or_clauses$ebnf$2"],
    "postprocess": function postprocess(_ref7) {
      var _ref8 = _slicedToArray(_ref7, 2),
          expressions = _ref8[0],
          clauses = _ref8[1];

      return [].concat(_toConsumableArray(expressions), _toConsumableArray(clauses));
    }
  }, {
    "name": "clause$subexpression$1",
    "symbols": ["limit_clause"]
  }, {
    "name": "clause$subexpression$1",
    "symbols": ["select_clause"]
  }, {
    "name": "clause$subexpression$1",
    "symbols": ["other_clause"]
  }, {
    "name": "clause$subexpression$1",
    "symbols": ["set_operation"]
  }, {
    "name": "clause",
    "symbols": ["clause$subexpression$1"],
    "postprocess": unwrap
  }, {
    "name": "limit_clause$ebnf$1",
    "symbols": ["commaless_expression"]
  }, {
    "name": "limit_clause$ebnf$1",
    "symbols": ["limit_clause$ebnf$1", "commaless_expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "limit_clause$ebnf$2$subexpression$1$ebnf$1",
    "symbols": ["expression"]
  }, {
    "name": "limit_clause$ebnf$2$subexpression$1$ebnf$1",
    "symbols": ["limit_clause$ebnf$2$subexpression$1$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "limit_clause$ebnf$2$subexpression$1",
    "symbols": [lexer.has("COMMA") ? {
      type: "COMMA"
    } : COMMA, "limit_clause$ebnf$2$subexpression$1$ebnf$1"]
  }, {
    "name": "limit_clause$ebnf$2",
    "symbols": ["limit_clause$ebnf$2$subexpression$1"],
    "postprocess": id
  }, {
    "name": "limit_clause$ebnf$2",
    "symbols": [],
    "postprocess": function postprocess() {
      return null;
    }
  }, {
    "name": "limit_clause",
    "symbols": [lexer.has("LIMIT") ? {
      type: "LIMIT"
    } : LIMIT, "limit_clause$ebnf$1", "limit_clause$ebnf$2"],
    "postprocess": function postprocess(_ref9) {
      var _ref10 = _slicedToArray(_ref9, 3),
          limitToken = _ref10[0],
          exp1 = _ref10[1],
          optional = _ref10[2];

      if (optional) {
        var _optional = _slicedToArray(optional, 2),
            comma = _optional[0],
            exp2 = _optional[1];

        return {
          type: _ast.NodeType.limit_clause,
          name: toKeywordNode(limitToken),
          offset: exp1,
          count: exp2
        };
      } else {
        return {
          type: _ast.NodeType.limit_clause,
          name: toKeywordNode(limitToken),
          count: exp1
        };
      }
    }
  }, {
    "name": "select_clause$subexpression$1$ebnf$1",
    "symbols": []
  }, {
    "name": "select_clause$subexpression$1$ebnf$1",
    "symbols": ["select_clause$subexpression$1$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "select_clause$subexpression$1",
    "symbols": ["all_columns_asterisk", "select_clause$subexpression$1$ebnf$1"]
  }, {
    "name": "select_clause$subexpression$1$ebnf$2",
    "symbols": []
  }, {
    "name": "select_clause$subexpression$1$ebnf$2",
    "symbols": ["select_clause$subexpression$1$ebnf$2", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "select_clause$subexpression$1",
    "symbols": ["asteriskless_expression", "select_clause$subexpression$1$ebnf$2"]
  }, {
    "name": "select_clause",
    "symbols": [lexer.has("RESERVED_SELECT") ? {
      type: "RESERVED_SELECT"
    } : RESERVED_SELECT, "select_clause$subexpression$1"],
    "postprocess": function postprocess(_ref11) {
      var _ref12 = _slicedToArray(_ref11, 2),
          nameToken = _ref12[0],
          _ref12$ = _slicedToArray(_ref12[1], 2),
          exp = _ref12$[0],
          expressions = _ref12$[1];

      return {
        type: _ast.NodeType.clause,
        name: toKeywordNode(nameToken),
        children: [exp].concat(_toConsumableArray(expressions))
      };
    }
  }, {
    "name": "all_columns_asterisk",
    "symbols": [lexer.has("ASTERISK") ? {
      type: "ASTERISK"
    } : ASTERISK],
    "postprocess": function postprocess() {
      return {
        type: _ast.NodeType.all_columns_asterisk
      };
    }
  }, {
    "name": "other_clause$ebnf$1",
    "symbols": []
  }, {
    "name": "other_clause$ebnf$1",
    "symbols": ["other_clause$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "other_clause",
    "symbols": [lexer.has("RESERVED_COMMAND") ? {
      type: "RESERVED_COMMAND"
    } : RESERVED_COMMAND, "other_clause$ebnf$1"],
    "postprocess": function postprocess(_ref13) {
      var _ref14 = _slicedToArray(_ref13, 2),
          nameToken = _ref14[0],
          children = _ref14[1];

      return {
        type: _ast.NodeType.clause,
        name: toKeywordNode(nameToken),
        children: children
      };
    }
  }, {
    "name": "set_operation$ebnf$1",
    "symbols": []
  }, {
    "name": "set_operation$ebnf$1",
    "symbols": ["set_operation$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "set_operation",
    "symbols": [lexer.has("RESERVED_SET_OPERATION") ? {
      type: "RESERVED_SET_OPERATION"
    } : RESERVED_SET_OPERATION, "set_operation$ebnf$1"],
    "postprocess": function postprocess(_ref15) {
      var _ref16 = _slicedToArray(_ref15, 2),
          nameToken = _ref16[0],
          children = _ref16[1];

      return {
        type: _ast.NodeType.set_operation,
        name: toKeywordNode(nameToken),
        children: children
      };
    }
  }, {
    "name": "expression$subexpression$1",
    "symbols": ["simple_expression"]
  }, {
    "name": "expression$subexpression$1",
    "symbols": ["between_predicate"]
  }, {
    "name": "expression$subexpression$1",
    "symbols": ["asterisk"]
  }, {
    "name": "expression$subexpression$1",
    "symbols": ["comma"]
  }, {
    "name": "expression",
    "symbols": ["expression$subexpression$1"],
    "postprocess": unwrap
  }, {
    "name": "asteriskless_expression$subexpression$1",
    "symbols": ["simple_expression"]
  }, {
    "name": "asteriskless_expression$subexpression$1",
    "symbols": ["between_predicate"]
  }, {
    "name": "asteriskless_expression$subexpression$1",
    "symbols": ["comma"]
  }, {
    "name": "asteriskless_expression",
    "symbols": ["asteriskless_expression$subexpression$1"],
    "postprocess": unwrap
  }, {
    "name": "commaless_expression$subexpression$1",
    "symbols": ["simple_expression"]
  }, {
    "name": "commaless_expression$subexpression$1",
    "symbols": ["between_predicate"]
  }, {
    "name": "commaless_expression$subexpression$1",
    "symbols": ["asterisk"]
  }, {
    "name": "commaless_expression",
    "symbols": ["commaless_expression$subexpression$1"],
    "postprocess": unwrap
  }, {
    "name": "simple_expression$subexpression$1",
    "symbols": ["array_subscript"]
  }, {
    "name": "simple_expression$subexpression$1",
    "symbols": ["function_call"]
  }, {
    "name": "simple_expression$subexpression$1",
    "symbols": ["property_access"]
  }, {
    "name": "simple_expression$subexpression$1",
    "symbols": ["parenthesis"]
  }, {
    "name": "simple_expression$subexpression$1",
    "symbols": ["curly_braces"]
  }, {
    "name": "simple_expression$subexpression$1",
    "symbols": ["square_brackets"]
  }, {
    "name": "simple_expression$subexpression$1",
    "symbols": ["expression_token"]
  }, {
    "name": "simple_expression",
    "symbols": ["simple_expression$subexpression$1"],
    "postprocess": unwrap
  }, {
    "name": "array_subscript",
    "symbols": [lexer.has("ARRAY_IDENTIFIER") ? {
      type: "ARRAY_IDENTIFIER"
    } : ARRAY_IDENTIFIER, "square_brackets"],
    "postprocess": function postprocess(_ref17) {
      var _ref18 = _slicedToArray(_ref17, 2),
          arrayToken = _ref18[0],
          brackets = _ref18[1];

      return {
        type: _ast.NodeType.array_subscript,
        array: {
          type: _ast.NodeType.identifier,
          text: arrayToken.text
        },
        parenthesis: brackets
      };
    }
  }, {
    "name": "array_subscript",
    "symbols": [lexer.has("ARRAY_KEYWORD") ? {
      type: "ARRAY_KEYWORD"
    } : ARRAY_KEYWORD, "square_brackets"],
    "postprocess": function postprocess(_ref19) {
      var _ref20 = _slicedToArray(_ref19, 2),
          arrayToken = _ref20[0],
          brackets = _ref20[1];

      return {
        type: _ast.NodeType.array_subscript,
        array: toKeywordNode(arrayToken),
        parenthesis: brackets
      };
    }
  }, {
    "name": "function_call",
    "symbols": [lexer.has("RESERVED_FUNCTION_NAME") ? {
      type: "RESERVED_FUNCTION_NAME"
    } : RESERVED_FUNCTION_NAME, "parenthesis"],
    "postprocess": function postprocess(_ref21) {
      var _ref22 = _slicedToArray(_ref21, 2),
          nameToken = _ref22[0],
          parens = _ref22[1];

      return {
        type: _ast.NodeType.function_call,
        name: toKeywordNode(nameToken),
        parenthesis: parens
      };
    }
  }, {
    "name": "parenthesis",
    "symbols": [{
      "literal": "("
    }, "expressions_or_clauses", {
      "literal": ")"
    }],
    "postprocess": function postprocess(_ref23) {
      var _ref24 = _slicedToArray(_ref23, 3),
          open = _ref24[0],
          children = _ref24[1],
          close = _ref24[2];

      return {
        type: _ast.NodeType.parenthesis,
        children: children,
        openParen: "(",
        closeParen: ")"
      };
    }
  }, {
    "name": "curly_braces$ebnf$1",
    "symbols": []
  }, {
    "name": "curly_braces$ebnf$1",
    "symbols": ["curly_braces$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "curly_braces",
    "symbols": [{
      "literal": "{"
    }, "curly_braces$ebnf$1", {
      "literal": "}"
    }],
    "postprocess": function postprocess(_ref25) {
      var _ref26 = _slicedToArray(_ref25, 3),
          open = _ref26[0],
          children = _ref26[1],
          close = _ref26[2];

      return {
        type: _ast.NodeType.parenthesis,
        children: children,
        openParen: "{",
        closeParen: "}"
      };
    }
  }, {
    "name": "square_brackets$ebnf$1",
    "symbols": []
  }, {
    "name": "square_brackets$ebnf$1",
    "symbols": ["square_brackets$ebnf$1", "expression"],
    "postprocess": function postprocess(d) {
      return d[0].concat([d[1]]);
    }
  }, {
    "name": "square_brackets",
    "symbols": [{
      "literal": "["
    }, "square_brackets$ebnf$1", {
      "literal": "]"
    }],
    "postprocess": function postprocess(_ref27) {
      var _ref28 = _slicedToArray(_ref27, 3),
          open = _ref28[0],
          children = _ref28[1],
          close = _ref28[2];

      return {
        type: _ast.NodeType.parenthesis,
        children: children,
        openParen: "[",
        closeParen: "]"
      };
    }
  }, {
    "name": "property_access$subexpression$1",
    "symbols": ["identifier"]
  }, {
    "name": "property_access$subexpression$1",
    "symbols": ["array_subscript"]
  }, {
    "name": "property_access$subexpression$1",
    "symbols": ["all_columns_asterisk"]
  }, {
    "name": "property_access",
    "symbols": ["simple_expression", lexer.has("DOT") ? {
      type: "DOT"
    } : DOT, "property_access$subexpression$1"],
    "postprocess": // Allowing property to be <array_subscript> is currently a hack.
    // A better way would be to allow <property_access> on the left side of array_subscript,
    // but we currently can't do that because of another hack that requires
    // %ARRAY_IDENTIFIER on the left side of <array_subscript>.
    function postprocess(_ref29) {
      var _ref30 = _slicedToArray(_ref29, 3),
          object = _ref30[0],
          dot = _ref30[1],
          _ref30$ = _slicedToArray(_ref30[2], 1),
          property = _ref30$[0];

      return {
        type: _ast.NodeType.property_access,
        object: object,
        property: property
      };
    }
  }, {
    "name": "between_predicate",
    "symbols": [lexer.has("BETWEEN") ? {
      type: "BETWEEN"
    } : BETWEEN, "commaless_expression", lexer.has("AND") ? {
      type: "AND"
    } : AND, "commaless_expression"],
    "postprocess": function postprocess(_ref31) {
      var _ref32 = _slicedToArray(_ref31, 4),
          betweenToken = _ref32[0],
          expr1 = _ref32[1],
          andToken = _ref32[2],
          expr2 = _ref32[3];

      return {
        type: _ast.NodeType.between_predicate,
        between: toKeywordNode(betweenToken),
        expr1: [expr1],
        and: toKeywordNode(andToken),
        expr2: [expr2]
      };
    }
  }, {
    "name": "comma$subexpression$1",
    "symbols": [lexer.has("COMMA") ? {
      type: "COMMA"
    } : COMMA]
  }, {
    "name": "comma",
    "symbols": ["comma$subexpression$1"],
    "postprocess": function postprocess(_ref33) {
      var _ref34 = _slicedToArray(_ref33, 1),
          _ref34$ = _slicedToArray(_ref34[0], 1),
          token = _ref34$[0];

      return {
        type: _ast.NodeType.comma
      };
    }
  }, {
    "name": "asterisk$subexpression$1",
    "symbols": [lexer.has("ASTERISK") ? {
      type: "ASTERISK"
    } : ASTERISK]
  }, {
    "name": "asterisk",
    "symbols": ["asterisk$subexpression$1"],
    "postprocess": function postprocess(_ref35) {
      var _ref36 = _slicedToArray(_ref35, 1),
          _ref36$ = _slicedToArray(_ref36[0], 1),
          token = _ref36$[0];

      return {
        type: _ast.NodeType.operator,
        text: token.text
      };
    }
  }, {
    "name": "expression_token$subexpression$1",
    "symbols": ["operator"]
  }, {
    "name": "expression_token$subexpression$1",
    "symbols": ["identifier"]
  }, {
    "name": "expression_token$subexpression$1",
    "symbols": ["parameter"]
  }, {
    "name": "expression_token$subexpression$1",
    "symbols": ["literal"]
  }, {
    "name": "expression_token$subexpression$1",
    "symbols": ["keyword"]
  }, {
    "name": "expression_token$subexpression$1",
    "symbols": ["comment"]
  }, {
    "name": "expression_token",
    "symbols": ["expression_token$subexpression$1"],
    "postprocess": unwrap
  }, {
    "name": "operator$subexpression$1",
    "symbols": [lexer.has("OPERATOR") ? {
      type: "OPERATOR"
    } : OPERATOR]
  }, {
    "name": "operator",
    "symbols": ["operator$subexpression$1"],
    "postprocess": function postprocess(_ref37) {
      var _ref38 = _slicedToArray(_ref37, 1),
          _ref38$ = _slicedToArray(_ref38[0], 1),
          token = _ref38$[0];

      return {
        type: _ast.NodeType.operator,
        text: token.text
      };
    }
  }, {
    "name": "identifier$subexpression$1",
    "symbols": [lexer.has("IDENTIFIER") ? {
      type: "IDENTIFIER"
    } : IDENTIFIER]
  }, {
    "name": "identifier$subexpression$1",
    "symbols": [lexer.has("QUOTED_IDENTIFIER") ? {
      type: "QUOTED_IDENTIFIER"
    } : QUOTED_IDENTIFIER]
  }, {
    "name": "identifier$subexpression$1",
    "symbols": [lexer.has("VARIABLE") ? {
      type: "VARIABLE"
    } : VARIABLE]
  }, {
    "name": "identifier",
    "symbols": ["identifier$subexpression$1"],
    "postprocess": function postprocess(_ref39) {
      var _ref40 = _slicedToArray(_ref39, 1),
          _ref40$ = _slicedToArray(_ref40[0], 1),
          token = _ref40$[0];

      return {
        type: _ast.NodeType.identifier,
        text: token.text
      };
    }
  }, {
    "name": "parameter$subexpression$1",
    "symbols": [lexer.has("NAMED_PARAMETER") ? {
      type: "NAMED_PARAMETER"
    } : NAMED_PARAMETER]
  }, {
    "name": "parameter$subexpression$1",
    "symbols": [lexer.has("QUOTED_PARAMETER") ? {
      type: "QUOTED_PARAMETER"
    } : QUOTED_PARAMETER]
  }, {
    "name": "parameter$subexpression$1",
    "symbols": [lexer.has("NUMBERED_PARAMETER") ? {
      type: "NUMBERED_PARAMETER"
    } : NUMBERED_PARAMETER]
  }, {
    "name": "parameter$subexpression$1",
    "symbols": [lexer.has("POSITIONAL_PARAMETER") ? {
      type: "POSITIONAL_PARAMETER"
    } : POSITIONAL_PARAMETER]
  }, {
    "name": "parameter",
    "symbols": ["parameter$subexpression$1"],
    "postprocess": function postprocess(_ref41) {
      var _ref42 = _slicedToArray(_ref41, 1),
          _ref42$ = _slicedToArray(_ref42[0], 1),
          token = _ref42$[0];

      return {
        type: _ast.NodeType.parameter,
        key: token.key,
        text: token.text
      };
    }
  }, {
    "name": "literal$subexpression$1",
    "symbols": [lexer.has("NUMBER") ? {
      type: "NUMBER"
    } : NUMBER]
  }, {
    "name": "literal$subexpression$1",
    "symbols": [lexer.has("STRING") ? {
      type: "STRING"
    } : STRING]
  }, {
    "name": "literal",
    "symbols": ["literal$subexpression$1"],
    "postprocess": function postprocess(_ref43) {
      var _ref44 = _slicedToArray(_ref43, 1),
          _ref44$ = _slicedToArray(_ref44[0], 1),
          token = _ref44$[0];

      return {
        type: _ast.NodeType.literal,
        text: token.text
      };
    }
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("RESERVED_KEYWORD") ? {
      type: "RESERVED_KEYWORD"
    } : RESERVED_KEYWORD]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("RESERVED_PHRASE") ? {
      type: "RESERVED_PHRASE"
    } : RESERVED_PHRASE]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("RESERVED_DEPENDENT_CLAUSE") ? {
      type: "RESERVED_DEPENDENT_CLAUSE"
    } : RESERVED_DEPENDENT_CLAUSE]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("RESERVED_JOIN") ? {
      type: "RESERVED_JOIN"
    } : RESERVED_JOIN]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("CASE") ? {
      type: "CASE"
    } : CASE]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("END") ? {
      type: "END"
    } : END]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("AND") ? {
      type: "AND"
    } : AND]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("OR") ? {
      type: "OR"
    } : OR]
  }, {
    "name": "keyword$subexpression$1",
    "symbols": [lexer.has("XOR") ? {
      type: "XOR"
    } : XOR]
  }, {
    "name": "keyword",
    "symbols": ["keyword$subexpression$1"],
    "postprocess": function postprocess(_ref45) {
      var _ref46 = _slicedToArray(_ref45, 1),
          _ref46$ = _slicedToArray(_ref46[0], 1),
          token = _ref46$[0];

      return toKeywordNode(token);
    }
  }, {
    "name": "comment",
    "symbols": [lexer.has("LINE_COMMENT") ? {
      type: "LINE_COMMENT"
    } : LINE_COMMENT],
    "postprocess": function postprocess(_ref47) {
      var _ref48 = _slicedToArray(_ref47, 1),
          token = _ref48[0];

      return {
        type: _ast.NodeType.line_comment,
        text: token.text,
        precedingWhitespace: token.precedingWhitespace
      };
    }
  }, {
    "name": "comment",
    "symbols": [lexer.has("BLOCK_COMMENT") ? {
      type: "BLOCK_COMMENT"
    } : BLOCK_COMMENT],
    "postprocess": function postprocess(_ref49) {
      var _ref50 = _slicedToArray(_ref49, 1),
          token = _ref50[0];

      return {
        type: _ast.NodeType.block_comment,
        text: token.text
      };
    }
  }],
  ParserStart: "main"
};
var _default = grammar;
exports["default"] = _default;
module.exports = exports.default;
//# sourceMappingURL=grammar.js.map